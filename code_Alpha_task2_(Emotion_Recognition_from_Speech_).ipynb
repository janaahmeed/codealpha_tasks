{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaahmeed/codealpha_tasks/blob/main/code_Alpha_task2_(Emotion_Recognition_from_Speech_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P8UTA402oj4B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RDUKFjCopm4",
        "outputId": "eabe132e-5d25-40db-eb2a-ea28bd1d91db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'toronto-emotional-speech-set-tess' dataset.\n",
            "Path to dataset files: /kaggle/input/toronto-emotional-speech-set-tess\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ejlok1/toronto-emotional-speech-set-tess\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkvTKsVo9wNr"
      },
      "source": [
        "After framing, each frame is multiplied by a Hamming window to reduce spectral leakage before silence detection and further feature extraction.  \n",
        "# When you use librosa.feature.mfcc, framing + windowing (Hamming) are already applied internally by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fkKh1QKCnqF"
      },
      "source": [
        "y>> the audio time-series signal , Compute MFCC features from audio signal lf sampled at fs Hz\n",
        "y(t) = audio_signal\n",
        "mfcc(y=audio_signal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q6_FrhR_wi9u"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "def display_wave (data,sr,emotion):\n",
        " plt.rcParams['figure.figsize'] = (18,4)\n",
        " plt.title(emotion,size=20)\n",
        " librosa.display.waveplot(data,sr=sr)\n",
        " plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Always join files with root, never dirs."
      ],
      "metadata": {
        "id": "rRI2SDUd3lTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGHFTjW8qH_U",
        "outputId": "1ce0d5e2-3199-4027-aab7-8b1623189986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5600,) (5600,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "x, y = [], []\n",
        "emotion_map = {\n",
        "    \"angry\": 0,\n",
        "    \"disgust\": 1,\n",
        "    \"fear\": 2,\n",
        "    \"happy\": 3,\n",
        "    \"neutral\": 4,\n",
        "    \"sad\": 5,\n",
        "    \"ps\": 6\n",
        "}\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for _file in files:\n",
        "        if _file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(root, _file)\n",
        "\n",
        "            lf, fs = librosa.load(file_path, duration=3.0)\n",
        "\n",
        "            y_trimmed, _ = librosa.effects.trim(lf ,top_db=25 )  # 20–30 is common for speech\n",
        "\n",
        "            mfccs = librosa.feature.mfcc(\n",
        "                y=y_trimmed,\n",
        "                sr=fs,\n",
        "                n_mfcc=40,\n",
        "                n_fft=2048,\n",
        "                hop_length=512,\n",
        "                window='hamming')\n",
        "            mfccs = mfccs.T # (time_steps, n_mfcc)\n",
        "            # Why? LSTM expects time dimension first\n",
        "\n",
        "            x.append(mfccs)\n",
        "            emo_str = _file.split(\"_\")[-1].replace(\".wav\", \"\")\n",
        "            emo = emotion_map[emo_str]\n",
        "            y.append(emo)\n",
        "\n",
        "\n",
        "#(n_mfcc, time_frames) >>shape mfcc\n",
        "\n",
        "\n",
        "#NumPy arrays require equal shapes\n",
        "#Your MFCCs are variable-length sequences >> so we neednot ( Pad for CNN / Use sequence models (LSTM) / Use tf.keras.preprocessing.sequence.pad_sequences)\n",
        "#“Don’t force uniform shape — store each MFCC as a separate object” if duration is fixed we donot need for it\n",
        "#so type object\n",
        "x = np.array(x, dtype=object)\n",
        "y = np.array(y)\n",
        "\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "eag1__p2v8-k",
        "outputId": "60555fcc-9051-4592-bbc8-1b7c244b6ffd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGdCAYAAADpBYyuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGgtJREFUeJzt3X90lnd9//FXQpuEntrqDhB+mIm/Kq1WqDA4mbPWnkz8cdjpH3Oc6hFOrOxrLWe12WrNLGRdtdF9BdkcmhXl6Pccu+LqdPPQg3Y5Tac2PRyhbPOsrT/aDk5LAsxCHG1JTfL9w2NcPgSENOSG5PE45zqHfO7Pleud/tPnue7rTqqGhoaGAgDAsOpKDwAAcLYRSAAABYEEAFAQSAAABYEEAFAQSAAABYEEAFAQSAAAhfMqPcBEGxwczNNPP52XvOQlqaqqqvQ4AMApGBoays9//vPMnTs31dVn/v7OlAukp59+Og0NDZUeAwAYg3379uXlL3/5Gb/OlAukl7zkJUl++R/4oosuqvA0AMCp6OvrS0NDw/D/x8+0KRdIv3pb7aKLLhJIAHCOmajHYzykDQBQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAIWKBtK//uu/ZsWKFZk7d26qqqryzW9+8zee09XVlTe96U2pra3Na17zmnz5y18+43MCAFNLRQPp6NGjWbhwYTZv3nxK+5944om8+93vztve9rbs2bMnH/nIR/LBD34w3/72t8/wpADAVFLRP1b7zne+M+985ztPeX9HR0de+cpXZsOGDUmSSy+9NN/73vfy2c9+NsuXLz9TYwIAU8w59QxSd3d3mpqaRqwtX7483d3dJzzn2LFj6evrG3EAAJxMRe8gna6enp7U19ePWKuvr09fX1+ee+65TJ8+/bhz2tvbc9tttx23fuWtf589f/N/svjm/5ck2fV/Vw3/uzQer5X7Tvaaa7u2a7u2a7u2a4/8/lfe+vej7jtTzqk7SGPR2tqaI0eODB/79u2r9EgAwFnunLqDNHv27PT29o5Y6+3tzUUXXTTq3aMkqa2tTW1t7USMBwBMEufUHaTGxsZ0dnaOWLvvvvvS2NhYoYkAgMmoooH0P//zP9mzZ0/27NmT5Jcf49+zZ0/27t2b5Jdvj61atWp4/4c+9KE8/vjj+ehHP5pHH300n//85/O1r30tN910UyXGBwAmqYoG0g9+8INcccUVueKKK5IkLS0tueKKK7J+/fokyf79+4djKUle+cpXZvv27bnvvvuycOHCbNiwIV/84hd9xB8AGFcVfQbpqquuytDQ0AlfH+23ZF911VV5+OGHz+BUAMBUd049gwQAMBEEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAoeKBtHnz5syfPz91dXVZtmxZdu7cedL9mzZtyute97pMnz49DQ0Nuemmm/L8889P0LQAwFRQ0UDatm1bWlpa0tbWlt27d2fhwoVZvnx5Dhw4MOr+u+66Kx/72MfS1taWRx55JF/60peybdu2/Pmf//kETw4ATGYVDaSNGzdmzZo1aW5uzmWXXZaOjo5ccMEF2bp166j7H3zwwbz5zW/Oe9/73syfPz9vf/vbc+211/7Gu04AAKejYoHU39+fXbt2pamp6dfDVFenqakp3d3do57zu7/7u9m1a9dwED3++OO599578653veuE1zl27Fj6+vpGHAAAJ3NepS586NChDAwMpL6+fsR6fX19Hn300VHPee9735tDhw7l937v9zI0NJRf/OIX+dCHPnTSt9ja29tz2223jevsAMDkVvGHtE9HV1dX7rjjjnz+85/P7t2784//+I/Zvn17br/99hOe09ramiNHjgwf+/btm8CJAYBzUcXuIM2YMSPTpk1Lb2/viPXe3t7Mnj171HPWrVuX97///fngBz+YJLn88stz9OjR/PEf/3E+/vGPp7r6+N6rra1NbW3t+P8AAMCkVbE7SDU1NVm8eHE6OzuH1wYHB9PZ2ZnGxsZRz3n22WePi6Bp06YlSYaGhs7csADAlFKxO0hJ0tLSktWrV2fJkiVZunRpNm3alKNHj6a5uTlJsmrVqsybNy/t7e1JkhUrVmTjxo254oorsmzZsvzkJz/JunXrsmLFiuFQAgB4sSoaSCtXrszBgwezfv369PT0ZNGiRdmxY8fwg9t79+4dccfo1ltvTVVVVW699dY89dRTmTlzZlasWJFPfvKTlfoRAIBJqKKBlCRr167N2rVrR32tq6trxNfnnXde2tra0tbWNgGTAQBT1Tn1KTYAgIkgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKAgkAAACgIJAKBQ8UDavHlz5s+fn7q6uixbtiw7d+486f7Dhw/nhhtuyJw5c1JbW5tLLrkk99577wRNCwBMBedV8uLbtm1LS0tLOjo6smzZsmzatCnLly/PY489llmzZh23v7+/P7//+7+fWbNm5Z577sm8efPyX//1X3npS1868cMDAJNWRQNp48aNWbNmTZqbm5MkHR0d2b59e7Zu3ZqPfexjx+3funVrfvazn+XBBx/M+eefnySZP3/+RI4MAEwBFXuLrb+/P7t27UpTU9Ovh6muTlNTU7q7u0c955//+Z/T2NiYG264IfX19XnDG96QO+64IwMDAye8zrFjx9LX1zfiAAA4mYoF0qFDhzIwMJD6+voR6/X19enp6Rn1nMcffzz33HNPBgYGcu+992bdunXZsGFDPvGJT5zwOu3t7bn44ouHj4aGhnH9OQCAyafiD2mfjsHBwcyaNSt33nlnFi9enJUrV+bjH/94Ojo6TnhOa2trjhw5Mnzs27dvAicGAM5FFXsGacaMGZk2bVp6e3tHrPf29mb27NmjnjNnzpycf/75mTZt2vDapZdemp6envT396empua4c2pra1NbWzu+wwMAk1rF7iDV1NRk8eLF6ezsHF4bHBxMZ2dnGhsbRz3nzW9+c37yk59kcHBweO1HP/pR5syZM2ocAQCMRUXfYmtpacmWLVvyla98JY888kiuv/76HD16dPhTbatWrUpra+vw/uuvvz4/+9nPcuONN+ZHP/pRtm/fnjvuuCM33HBDpX4EAGASqujH/FeuXJmDBw9m/fr16enpyaJFi7Jjx47hB7f37t2b6upfN1xDQ0O+/e1v56abbsob3/jGzJs3LzfeeGNuueWWSv0IAMAkVNFASpK1a9dm7dq1o77W1dV13FpjY2MeeuihMzwVADCVnVOfYgMAmAgCCQCgMKZAuvrqq3P48OHj1vv6+nL11Ve/2JkAACpqTIHU1dWV/v7+49aff/75fPe7333RQwEAVNJpPaT97//+78P//s///M8RfxJkYGAgO3bsyLx588ZvOgCACjitQFq0aFGqqqpSVVU16ltp06dPz+c+97lxGw4AoBJOK5CeeOKJDA0N5VWvelV27tyZmTNnDr9WU1OTWbNmjfgzIAAA56LTCqRXvOIVSTLiT30AAEw2Y/5FkT/+8Y9z//3358CBA8cF0/r161/0YAAAlTKmQNqyZUuuv/76zJgxI7Nnz05VVdXwa1VVVQIJADinjSmQPvGJT+STn/ykv4EGAExKY/o9SM8880ze8573jPcsAABnhTEF0nve85585zvfGe9ZAADOCmN6i+01r3lN1q1bl4ceeiiXX355zj///BGv/8mf/Mm4DAcAUAljCqQ777wzF154YR544IE88MADI16rqqoSSADAOW1MgfTEE0+M9xwAAGeNMT2DBAAwmY3pDtIHPvCBk76+devWMQ0DAHA2GFMgPfPMMyO+fuGFF/LDH/4whw8fHvWP2AIAnEvGFEjf+MY3jlsbHBzM9ddfn1e/+tUveigAgEoat2eQqqur09LSks9+9rPj9S0BACpiXB/S/ulPf5pf/OIX4/ktAQAm3JjeYmtpaRnx9dDQUPbv35/t27dn9erV4zIYAECljCmQHn744RFfV1dXZ+bMmdmwYcNv/IQbAMDZbkyBdP/994/3HAAAZ40xBdKvHDx4MI899liS5HWve11mzpw5LkMBAFTSmB7SPnr0aD7wgQ9kzpw5ufLKK3PllVdm7ty5ue666/Lss8+O94wAABNqTIHU0tKSBx54IN/61rdy+PDhHD58OP/0T/+UBx54IH/6p3863jMCAEyoMb3F9vWvfz333HNPrrrqquG1d73rXZk+fXr+6I/+KF/4whfGaz4AgAk3pjtIzz77bOrr649bnzVrlrfYAIBz3pgCqbGxMW1tbXn++eeH15577rncdtttaWxsHLfhAAAqYUxvsW3atCnveMc78vKXvzwLFy5Mkvzbv/1bamtr853vfGdcBwQAmGhjCqTLL788P/7xj/PVr341jz76aJLk2muvzfve975Mnz59XAcEAJhoYwqk9vb21NfXZ82aNSPWt27dmoMHD+aWW24Zl+EAACphTM8g/d3f/V0WLFhw3PrrX//6dHR0vOihAAAqaUyB1NPTkzlz5hy3PnPmzOzfv/9FDwUAUEljCqSGhoZ8//vfP279+9//fubOnfuihwIAqKQxPYO0Zs2afOQjH8kLL7yQq6++OknS2dmZj370o36TNgBwzhtTIN1888357//+73z4wx9Of39/kqSuri633HJLWltbx3VAAICJNqZAqqqqyqc//emsW7cujzzySKZPn57Xvva1qa2tHe/5AAAm3JgC6VcuvPDC/M7v/M54zQIAcFYY00PaAACTmUACACgIJACAgkACACgIJACAgkACACgIJACAgkACACgIJACAgkACACgIJACAgkACACgIJACAgkACACgIJACAgkACACgIJACAgkACACicFYG0efPmzJ8/P3V1dVm2bFl27tx5SufdfffdqaqqyjXXXHNmBwQAppSKB9K2bdvS0tKStra27N69OwsXLszy5ctz4MCBk5735JNP5s/+7M/ylre8ZYImBQCmiooH0saNG7NmzZo0NzfnsssuS0dHRy644IJs3br1hOcMDAzkfe97X2677ba86lWvmsBpAYCpoKKB1N/fn127dqWpqWl4rbq6Ok1NTenu7j7heX/5l3+ZWbNm5brrrvuN1zh27Fj6+vpGHAAAJ1PRQDp06FAGBgZSX18/Yr2+vj49PT2jnvO9730vX/rSl7Jly5ZTukZ7e3suvvji4aOhoeFFzw0ATG4Vf4vtdPz85z/P+9///mzZsiUzZsw4pXNaW1tz5MiR4WPfvn1neEoA4Fx3XiUvPmPGjEybNi29vb0j1nt7ezN79uzj9v/0pz/Nk08+mRUrVgyvDQ4OJknOO++8PPbYY3n1q1894pza2trU1taegekBgMmqoneQampqsnjx4nR2dg6vDQ4OprOzM42NjcftX7BgQf7jP/4je/bsGT7+4A/+IG9729uyZ88eb58BAOOioneQkqSlpSWrV6/OkiVLsnTp0mzatClHjx5Nc3NzkmTVqlWZN29e2tvbU1dXlze84Q0jzn/pS1+aJMetAwCMVcUDaeXKlTl48GDWr1+fnp6eLFq0KDt27Bh+cHvv3r2prj6nHpUCAM5xFQ+kJFm7dm3Wrl076mtdXV0nPffLX/7y+A8EAExpbs0AABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBAQSABABQEEgBA4awIpM2bN2f+/Pmpq6vLsmXLsnPnzhPu3bJlS97ylrfkZS97WV72spelqanppPsBAE5XxQNp27ZtaWlpSVtbW3bv3p2FCxdm+fLlOXDgwKj7u7q6cu211+b+++9Pd3d3Ghoa8va3vz1PPfXUBE8OAExWFQ+kjRs3Zs2aNWlubs5ll12Wjo6OXHDBBdm6deuo+7/61a/mwx/+cBYtWpQFCxbki1/8YgYHB9PZ2TnBkwMAk1VFA6m/vz+7du1KU1PT8Fp1dXWamprS3d19St/j2WefzQsvvJDf+q3fGvX1Y8eOpa+vb8QBAHAyFQ2kQ4cOZWBgIPX19SPW6+vr09PTc0rf45ZbbsncuXNHRNb/1t7enosvvnj4aGhoeNFzAwCTW8XfYnsxPvWpT+Xuu+/ON77xjdTV1Y26p7W1NUeOHBk+9u3bN8FTAgDnmvMqefEZM2Zk2rRp6e3tHbHe29ub2bNnn/Tcz3zmM/nUpz6Vf/mXf8kb3/jGE+6rra1NbW3tuMwLAEwNFb2DVFNTk8WLF494wPpXD1w3Njae8Ly/+qu/yu23354dO3ZkyZIlEzEqADCFVPQOUpK0tLRk9erVWbJkSZYuXZpNmzbl6NGjaW5uTpKsWrUq8+bNS3t7e5Lk05/+dNavX5+77ror8+fPH35W6cILL8yFF15YsZ8DAJg8Kh5IK1euzMGDB7N+/fr09PRk0aJF2bFjx/CD23v37k119a9vdH3hC19If39//vAP/3DE92lra8tf/MVfTOToAMAkVfFASpK1a9dm7dq1o77W1dU14usnn3zyzA8EAExp5/Sn2AAAzgSBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAAWBBABQEEgAAIWzIpA2b96c+fPnp66uLsuWLcvOnTtPuv8f/uEfsmDBgtTV1eXyyy/PvffeO0GTAgBTQcUDadu2bWlpaUlbW1t2796dhQsXZvny5Tlw4MCo+x988MFce+21ue666/Lwww/nmmuuyTXXXJMf/vCHEzw5ADBZVTyQNm7cmDVr1qS5uTmXXXZZOjo6csEFF2Tr1q2j7v/rv/7rvOMd78jNN9+cSy+9NLfffnve9KY35W//9m8neHIAYLI6r5IX7+/vz65du9La2jq8Vl1dnaampnR3d496Tnd3d1paWkasLV++PN/85jdH3X/s2LEcO3Zs+OsjR44kSQb6n0tfX18Gjj2XJCP+XRqP18p9ru3aru3aru3arn0a1+7/5b+HhoZG3T/uhiroqaeeGkoy9OCDD45Yv/nmm4eWLl066jnnn3/+0F133TVibfPmzUOzZs0adX9bW9tQEofD4XA4HJPg+PrXvz4+EfIbVPwttjOttbU1R44cGT4eeuihSo8EAIzR/v37J+Q6FX2LbcaMGZk2bVp6e3tHrPf29mb27NmjnjN79uzT2l9bW5va2trhry+66KIXOTUAUCnV1RNzb6eid5BqamqyePHidHZ2Dq8NDg6ms7MzjY2No57T2Ng4Yn+S3HfffSfcDwBwuip6BylJWlpasnr16ixZsiRLly7Npk2bcvTo0TQ3NydJVq1alXnz5qW9vT1JcuONN+atb31rNmzYkHe/+925++6784Mf/CB33nlnJX8MAGAymZAnnX6Dz33uc0O//du/PVRTUzO0dOnSoYceemj4tbe+9a1Dq1evHrH/a1/72tAll1wyVFNTM/T6179+aPv27ad8rQMHDgzNmDGj4g+ZORwOh8PhOP3ju9/97njlx0lVDQ1N1OflAADODZP+U2wAAKdLIAEAFAQSAEBBIAEAFCr+Mf8zafr06Xn++ecrPQYAUGF1dXV57rnR/+7baCb1HaT//UdqAYCp63R/A/eU+Zh/VVVVpUcAACro2LFjqampOaW9k/oOEgDArzz99NOnvHdKBNLGjRsrPQIAUGH79+8/5b1TIpC6uroqPQIAUGGn87jNlAikb33rW5UeAQCosGeeeeaU907qQBocHMwll1xS6TEAgLPAxRdffMp7J/Wn2F7xildk7969lR4DAKiw+vr6PPHEE5k+ffop7Z/UgeSj/QBAkjzyyCNZsGDBKe+f1L9JexK3HwBwBk3qZ5AAAMZCIAEAFAQSAEBBIAEAFAQSAEBBIAEAFAQSAEBBIAEAFAQSAEBBIAEAFAQSAEBBIAEAFP4/44hnPh+XXh8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H6hwlBba6e5_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "x=tf.keras.preprocessing.sequence.pad_sequences(x ,padding='post')\n",
        "\n",
        "#for conv2d new dimansion to adapt MFCC inputs for convolutional layers.\n",
        "x=x[..., np.newaxis]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbdIlb6h6Ani"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV9qKvGaFgvp"
      },
      "source": [
        "//CNN / LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "itYuWWoAPjg8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "skkvQQJwN1oH"
      },
      "outputs": [],
      "source": [
        "X_train = (X_train - X_train.mean()) / X_train.std()\n",
        "X_test  = (X_test  - X_train.mean()) / X_train.std()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P517s3qCN6CM",
        "outputId": "747fc25a-99fc-4553-9561-f68f280345c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([640, 640, 640, 640, 640, 640, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.bincount(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9_wacgGEtan"
      },
      "source": [
        "MFCC features have limited frequency resolution, so aggressive pooling across both axes may collapse feature maps.\n",
        "We therefore apply pooling mainly along the time axis and preserve frequency information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "XrUzzahxEms3",
        "outputId": "74d43820-7ccb-4557-98b2-41ace8207bd6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │         \u001b[38;5;34m1,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │       \u001b[38;5;34m131,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m5120\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m5,506,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,506,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,672,903\u001b[0m (21.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,672,903</span> (21.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,672,519\u001b[0m (21.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,672,519</span> (21.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, BatchNormalization,\n",
        "    TimeDistributed, Flatten,\n",
        "    LSTM, Dense, Dropout\n",
        ")\n",
        "num_classes= len(np.unique(y))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=X_train.shape[1:]))\n",
        "\n",
        "# CNN block 1\n",
        "model.add(Conv2D(64, (4, 4), activation='relu', padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 1)))  # ↓ time only (1-2)=-1\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CNN block 2 (SAFE kernel)\n",
        "model.add(Conv2D(128, (4, 4), activation='relu', padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Prepare for LSTM\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "# LSTM\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#output\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYYOn2hEJWx7",
        "outputId": "7155e530-8473-4664-ddbd-bb700e51064c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n"
          ]
        }
      ],
      "source": [
        "print(y_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BgsgpvN1YQ9",
        "outputId": "adb597bc-4f30-492b-d708-40df251651af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2011s\u001b[0m 18s/step - accuracy: 0.2531 - loss: 1.8208 - val_accuracy: 0.2824 - val_loss: 2.0893\n",
            "Epoch 2/20\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2039s\u001b[0m 18s/step - accuracy: 0.6424 - loss: 0.9820 - val_accuracy: 0.1920 - val_loss: 2.2616\n",
            "Epoch 3/20\n",
            "\u001b[1m 90/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:20\u001b[0m 17s/step - accuracy: 0.8183 - loss: 0.5655"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7at6h0EG9BjZ"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwDlyrgH9Wx3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Emotion Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsxyh3yH9FCU"
      },
      "outputs": [],
      "source": [
        "print(classification_report( y_test, y_pred, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "id": "rxa2NLqp6EmP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN97bm5kLcWNxAWzoZbOFqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}