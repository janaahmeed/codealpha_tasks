{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaahmeed/codealpha_tasks/blob/main/codeAlpha_task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P8UTA402oj4B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RDUKFjCopm4",
        "outputId": "f7e773e6-ddf8-4087-9808-2f697e3acf28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'toronto-emotional-speech-set-tess' dataset.\n",
            "Path to dataset files: /kaggle/input/toronto-emotional-speech-set-tess\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ejlok1/toronto-emotional-speech-set-tess\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkvTKsVo9wNr"
      },
      "source": [
        "After framing, each frame is multiplied by a Hamming window to reduce spectral leakage before silence detection and further feature extraction.  \n",
        "# When you use librosa.feature.mfcc, framing + windowing (Hamming) are already applied internally by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fkKh1QKCnqF"
      },
      "source": [
        "y>> the audio time-series signal , Compute MFCC features from audio signal lf sampled at fs Hz\n",
        "y(t) = audio_signal\n",
        "mfcc(y=audio_signal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q6_FrhR_wi9u"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "def display_wave (data,sr,emotion):\n",
        " plt.rcParams['figure.figsize'] = (18,4)\n",
        " plt.title(emotion,size=20)\n",
        " librosa.display.waveplot(data,sr=sr)\n",
        " plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Always join files with root, never dirs."
      ],
      "metadata": {
        "id": "rRI2SDUd3lTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGHFTjW8qH_U",
        "outputId": "94bf9835-f9bd-465f-da40-a462fea0a2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5600,) (5600,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "x, y = [], []\n",
        "emotion_map = {\n",
        "    \"angry\": 0,\n",
        "    \"disgust\": 1,\n",
        "    \"fear\": 2,\n",
        "    \"happy\": 3,\n",
        "    \"neutral\": 4,\n",
        "    \"sad\": 5,\n",
        "    \"ps\": 6\n",
        "}\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for _file in files:\n",
        "        if _file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(root, _file)\n",
        "\n",
        "            lf, fs = librosa.load(file_path, duration=3.0)\n",
        "\n",
        "            y_trimmed, _ = librosa.effects.trim(lf ,top_db=25 )  # 20–30 is common for speech\n",
        "\n",
        "            mfccs = librosa.feature.mfcc(\n",
        "                y=y_trimmed,\n",
        "                sr=fs,\n",
        "                n_mfcc=40,\n",
        "                n_fft=2048,\n",
        "                hop_length=512,\n",
        "                window='hamming')\n",
        "            mfccs = mfccs.T # (time_steps, n_mfcc)\n",
        "            # Why? LSTM expects time dimension first\n",
        "\n",
        "            x.append(mfccs)\n",
        "            emo_str = _file.split(\"_\")[-1].replace(\".wav\", \"\")\n",
        "            emo = emotion_map[emo_str]\n",
        "            y.append(emo)\n",
        "\n",
        "\n",
        "#(n_mfcc, time_frames) >>shape mfcc\n",
        "\n",
        "\n",
        "#NumPy arrays require equal shapes\n",
        "#Your MFCCs are variable-length sequences >> so we neednot ( Pad for CNN / Use sequence models (LSTM) / Use tf.keras.preprocessing.sequence.pad_sequences)\n",
        "#“Don’t force uniform shape — store each MFCC as a separate object” if duration is fixed we donot need for it\n",
        "#so type object\n",
        "x = np.array(x, dtype=object)\n",
        "y = np.array(y)\n",
        "\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "eag1__p2v8-k",
        "outputId": "33a92111-6248-4b8a-876d-d1e2a97299a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABcsAAAFfCAYAAACRLJSQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHwZJREFUeJzt3X903mV9//FX0tKkHH7utE1/0K0iKDKxZe3oyZwOOZlVPN3pztH1gMf2BOyOSM+AOCydtLFDib9au41qRrGHfc/RQycqbqecKssom1JPjy3VeQYoQmmnJG2HbbFAg0m+f+wYyckNtiHJ3eZ6PM65z0mu+3Plfuf683k+53PX9PX19QUAAAAAAApWW+0BAAAAAACg2sRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFG1/tAUZbb29vfv7zn+fMM89MTU1NtccBAAAAAKCCvr6+PPfcc5k+fXpqa0f+vu/iYvnPf/7zzJw5s9pjAAAAAABwHPbt25fzzjtvxD+nuFh+5plnJvm/Az7rrLOqPA0AAAAAAJUcOXIkM2fO7G+6I624WP7rR6+cddZZYjkAAAAAwElutB6n7Qs+AQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMWraiz/j//4jyxcuDDTp09PTU1N7rvvvt+6Z9u2bfmDP/iD1NXV5YILLsjdd9894nMCAAAAADC2VTWWHz16NLNnz86GDRuO6/qnnnoq73nPe/KOd7wju3fvzo033pgPfvCD+da3vjXCkwIAAAAAMJaNr+aHv/vd78673/3u476+vb09r3vd67J27dokyZve9KZ85zvfyec///ksWLBgpMYEAAAAAGCMO6WeWb59+/Y0NTUNWFuwYEG2b9/+inuOHTuWI0eODHgBAAAAAMDLVfXO8hPV2dmZhoaGAWsNDQ05cuRIXnjhhUycOHHQnra2tqxZs2bYZph78/8btr91Mtr52SVD2udcKhvL5+JMKnMulTmXypzLYM6kMudSmXOpzLkM5kwqcy6VOZfKnMtgzqQy51KZc6nMuQzmTAbqOfbCqH7eKXVn+VCsXLkyhw8f7n/t27ev2iMBAAAAAHCSOaXuLJ86dWq6uroGrHV1deWss86qeFd5ktTV1aWurm40xgMAAAAA4BR1St1Z3tjYmI6OjgFrDzzwQBobG6s0EQAAAAAAY0FVY/kvf/nL7N69O7t3706SPPXUU9m9e3f27t2b5P8eobJkyW+e0/OhD30oTz75ZD760Y/mscceyxe+8IX88z//c2666aZqjA8AAAAAwBhR1Vj+/e9/P5deemkuvfTSJElLS0suvfTSrF69OknyzDPP9IfzJHnd616XLVu25IEHHsjs2bOzdu3a3HXXXVmwYEFV5gcAAAAAYGyo6jPLL7/88vT19b3i+3fffXfFPY888sgITgUAAAAAQGlOqWeWAwAAAADASBDLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhVj+UbNmzIrFmzUl9fn/nz52fHjh2vev369evzxje+MRMnTszMmTNz00035cUXXxylaQEAAAAAGIuqGss3b96clpaWtLa2ZteuXZk9e3YWLFiQ/fv3V7z+K1/5Sm655Za0trbm0UcfzZe+9KVs3rw5f/M3fzPKkwMAAAAAMJZUNZavW7cuy5YtS3Nzcy6++OK0t7fn9NNPz6ZNmype//DDD+etb31rrr766syaNSvvfOc7c9VVV/3Wu9EBAAAAAODVVC2Wd3d3Z+fOnWlqavrNMLW1aWpqyvbt2yvu+aM/+qPs3LmzP44/+eSTuf/++3PllVe+4uccO3YsR44cGfACAAAAAICXG1+tDz548GB6enrS0NAwYL2hoSGPPfZYxT1XX311Dh48mD/+4z9OX19ffvWrX+VDH/rQqz6Gpa2tLWvWrBnW2QEAAAAAGFuq/gWfJ2Lbtm25/fbb84UvfCG7du3K17/+9WzZsiW33XbbK+5ZuXJlDh8+3P/at2/fKE4MAAAAAMCpoGp3lk+aNCnjxo1LV1fXgPWurq5MnTq14p5Vq1blAx/4QD74wQ8mSS655JIcPXo0f/mXf5mPfexjqa0d3P7r6upSV1c3/P8AAAAAAABjRtXuLJ8wYULmzp2bjo6O/rXe3t50dHSksbGx4p7nn39+UBAfN25ckqSvr2/khgUAAAAAYEyr2p3lSdLS0pKlS5dm3rx5ueyyy7J+/focPXo0zc3NSZIlS5ZkxowZaWtrS5IsXLgw69aty6WXXpr58+fniSeeyKpVq7Jw4cL+aA4AAAAAACeqqrF88eLFOXDgQFavXp3Ozs7MmTMnW7du7f/Sz7179w64k/zWW29NTU1Nbr311vzsZz/L5MmTs3Dhwnzyk5+s1r8AAAAAAMAYUNVYniTLly/P8uXLK763bdu2Ab+PHz8+ra2taW1tHYXJAAAAAAAoRdWeWQ4AAAAAACcLsRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8aoeyzds2JBZs2alvr4+8+fPz44dO171+kOHDuX666/PtGnTUldXlze84Q25//77R2laAAAAAADGovHV/PDNmzenpaUl7e3tmT9/ftavX58FCxbk8ccfz5QpUwZd393dnT/90z/NlClTcu+992bGjBl5+umnc84554z+8AAAAAAAjBlVjeXr1q3LsmXL0tzcnCRpb2/Pli1bsmnTptxyyy2Drt+0aVOeffbZPPzwwznttNOSJLNmzRrNkQEAAAAAGIOq9hiW7u7u7Ny5M01NTb8ZprY2TU1N2b59e8U9//Iv/5LGxsZcf/31aWhoyJvf/Obcfvvt6enpecXPOXbsWI4cOTLgBQAAAAAAL1e1WH7w4MH09PSkoaFhwHpDQ0M6Ozsr7nnyySdz7733pqenJ/fff39WrVqVtWvX5hOf+MQrfk5bW1vOPvvs/tfMmTOH9f8AAAAAAODUV/Uv+DwRvb29mTJlSu68887MnTs3ixcvzsc+9rG0t7e/4p6VK1fm8OHD/a99+/aN4sQAAAAAAJwKqvbM8kmTJmXcuHHp6uoasN7V1ZWpU6dW3DNt2rScdtppGTduXP/am970pnR2dqa7uzsTJkwYtKeuri51dXXDOzwAAAAAAGNK1e4snzBhQubOnZuOjo7+td7e3nR0dKSxsbHinre+9a154okn0tvb27/24x//ONOmTasYygEAAAAA4HhU9TEsLS0t2bhxY/7pn/4pjz76aK677rocPXo0zc3NSZIlS5Zk5cqV/ddfd911efbZZ3PDDTfkxz/+cbZs2ZLbb789119/fbX+BQAAAAAAxoCqPYYlSRYvXpwDBw5k9erV6ezszJw5c7J169b+L/3cu3dvamt/0/NnzpyZb33rW7npppvylre8JTNmzMgNN9yQFStWVOtfAAAAAABgDBhSLL/iiivy9a9/Peecc86A9SNHjmTRokX593//9+P+W8uXL8/y5csrvrdt27ZBa42Njfne9753IuMCAAAAAMCrGtJjWLZt25bu7u5B6y+++GL+8z//8zUPBQAAAAAAo+mE7iz/4Q9/2P/zf//3f6ezs7P/956enmzdujUzZswYvukAAAAAAGAUnFAsnzNnTmpqalJTU5Mrrrhi0PsTJ07MP/zDPwzbcAAAAAAAMBpOKJY/9dRT6evry/nnn58dO3Zk8uTJ/e9NmDAhU6ZMybhx44Z9SAAAAAAAGEknFMt/7/d+L0nS29s7IsMAAAAAAEA1nFAsf7mf/OQnefDBB7N///5B8Xz16tWveTAAAAAAABgtQ4rlGzduzHXXXZdJkyZl6tSpqamp6X+vpqZGLAcAAAAA4JQypFj+iU98Ip/85CezYsWK4Z4HAAAAAABGXe1QNv3iF7/I+973vuGeBQAAAAAAqmJIsfx973tfvv3tbw/3LAAAAAAAUBVDegzLBRdckFWrVuV73/teLrnkkpx22mkD3v+rv/qrYRkOAAAAAABGw5Bi+Z133pkzzjgjDz30UB566KEB79XU1IjlAAAAAACcUoYUy5966qnhngMAAAAAAKpmSM8sBwAAAACAsWRId5Zfc801r/r+pk2bhjQMAAAAAABUw5Bi+S9+8YsBv7/00kv50Y9+lEOHDuWKK64YlsEAAAAAAGC0DCmWf+Mb3xi01tvbm+uuuy6vf/3rX/NQAAAAAAAwmobtmeW1tbVpaWnJ5z//+eH6kwAAAAAAMCqG9Qs+f/rTn+ZXv/rVcP5JAAAAAAAYcUN6DEtLS8uA3/v6+vLMM89ky5YtWbp06bAMBgAAAAAAo2VIsfyRRx4Z8HttbW0mT56ctWvX5pprrhmWwQAAAAAAYLQMKZY/+OCDwz0HAAAAAABUzZBi+a8dOHAgjz/+eJLkjW98YyZPnjwsQwEAAAAAwGga0hd8Hj16NNdcc02mTZuWt7/97Xn729+e6dOn59prr83zzz8/3DMCAAAAAMCIGlIsb2lpyUMPPZR//dd/zaFDh3Lo0KF885vfzEMPPZSPfOQjwz0jAAAAAACMqCE9huVrX/ta7r333lx++eX9a1deeWUmTpyYv/iLv8gXv/jF4ZoPAAAAAABG3JDuLH/++efT0NAwaH3KlCkewwIAAAAAwClnSLG8sbExra2tefHFF/vXXnjhhaxZsyaNjY3DNhwAAAAAAIyGIT2GZf369XnXu96V8847L7Nnz06S/OAHP0hdXV2+/e1vD+uAAAAAAAAw0oYUyy+55JL85Cc/yZe//OU89thjSZKrrroq73//+zNx4sRhHRAAAAAAAEbakGJ5W1tbGhoasmzZsgHrmzZtyoEDB7JixYphGQ4AAAAAAEbDkJ5Z/o//+I+56KKLBq3//u//ftrb21/zUAAAAAAAMJqGFMs7Ozszbdq0QeuTJ0/OM88885qHAgAAAACA0TSkWD5z5sx897vfHbT+3e9+N9OnT3/NQwEAAAAAwGga0jPLly1blhtvvDEvvfRSrrjiiiRJR0dHPvrRj+YjH/nIsA4IAAAAAAAjbUix/Oabb87//u//5sMf/nC6u7uTJPX19VmxYkVWrlw5rAMCAAAAAMBIG1Isr6mpyac//emsWrUqjz76aCZOnJgLL7wwdXV1wz0fAAAAAACMuCHF8l8744wz8od/+IfDNQsAAAAAAFTFkL7gEwAAAAAAxhKxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKdFLF8w4YNmTVrVurr6zN//vzs2LHjuPbdc889qampyaJFi0Z2QAAAAAAAxrSqx/LNmzenpaUlra2t2bVrV2bPnp0FCxZk//79r7pvz549+eu//uu87W1vG6VJAQAAAAAYq6oey9etW5dly5alubk5F198cdrb23P66adn06ZNr7inp6cn73//+7NmzZqcf/75ozgtAAAAAABjUVVjeXd3d3bu3Jmmpqb+tdra2jQ1NWX79u2vuO9v//ZvM2XKlFx77bW/9TOOHTuWI0eODHgBAAAAAMDLVTWWHzx4MD09PWloaBiw3tDQkM7Ozop7vvOd7+RLX/pSNm7ceFyf0dbWlrPPPrv/NXPmzNc8NwAAAAAAY0vVH8NyIp577rl84AMfyMaNGzNp0qTj2rNy5cocPny4/7Vv374RnhIAAAAAgFPN+Gp++KRJkzJu3Lh0dXUNWO/q6srUqVMHXf/Tn/40e/bsycKFC/vXent7kyTjx4/P448/nte//vUD9tTV1aWurm4EpgcAAAAAYKyo6p3lEyZMyNy5c9PR0dG/1tvbm46OjjQ2Ng66/qKLLsp//dd/Zffu3f2vP/uzP8s73vGO7N692yNWAAAAAAAYkqreWZ4kLS0tWbp0aebNm5fLLrss69evz9GjR9Pc3JwkWbJkSWbMmJG2trbU19fnzW9+84D955xzTpIMWgcAAAAAgONV9Vi+ePHiHDhwIKtXr05nZ2fmzJmTrVu39n/p5969e1Nbe0o9Wh0AAAAAgFNM1WN5kixfvjzLly+v+N62bdtede/dd989/AMBAAAAAFAUt2wDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKd1LE8g0bNmTWrFmpr6/P/Pnzs2PHjle8duPGjXnb296Wc889N+eee26amppe9XoAAAAAAPhtqh7LN2/enJaWlrS2tmbXrl2ZPXt2FixYkP3791e8ftu2bbnqqqvy4IMPZvv27Zk5c2be+c535mc/+9koTw4AAAAAwFhR9Vi+bt26LFu2LM3Nzbn44ovT3t6e008/PZs2bap4/Ze//OV8+MMfzpw5c3LRRRflrrvuSm9vbzo6OkZ5cgAAAAAAxoqqxvLu7u7s3LkzTU1N/Wu1tbVpamrK9u3bj+tvPP/883nppZfyO7/zOxXfP3bsWI4cOTLgBQAAAAAAL1fVWH7w4MH09PSkoaFhwHpDQ0M6OzuP62+sWLEi06dPHxDcX66trS1nn312/2vmzJmveW4AAAAAAMaWqj+G5bX41Kc+lXvuuSff+MY3Ul9fX/GalStX5vDhw/2vffv2jfKUAAAAAACc7MZX88MnTZqUcePGpaura8B6V1dXpk6d+qp7P/e5z+VTn/pU/u3f/i1vectbXvG6urq61NXVDcu8AAAAAACMTVW9s3zChAmZO3fugC/n/PWXdTY2Nr7ivs985jO57bbbsnXr1sybN280RgUAAAAAYAyr6p3lSdLS0pKlS5dm3rx5ueyyy7J+/focPXo0zc3NSZIlS5ZkxowZaWtrS5J8+tOfzurVq/OVr3wls2bN6n+2+RlnnJEzzjijav8HAAAAAACnrqrH8sWLF+fAgQNZvXp1Ojs7M2fOnGzdurX/Sz/37t2b2trf3AD/xS9+Md3d3Xnve9874O+0trbm4x//+GiODgAAAADAGFH1WJ4ky5cvz/Llyyu+t23btgG/79mzZ+QHAgAAAACgKFV9ZjkAAAAAAJwMxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAUTywHAAAAAKB4YjkAAAAAAMUTywEAAAAAKJ5YDgAAAABA8cRyAAAAAACKJ5YDAAAAAFA8sRwAAAAAgOKJ5QAAAAAAFE8sBwAAAACgeGI5AAAAAADFE8sBAAAAACieWA4AAAAAQPHEcgAAAAAAiieWAwAAAABQPLEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAo3kkRyzds2JBZs2alvr4+8+fPz44dO171+q9+9au56KKLUl9fn0suuST333//KE0KAAAAAMBYVPVYvnnz5rS0tKS1tTW7du3K7Nmzs2DBguzfv7/i9Q8//HCuuuqqXHvttXnkkUeyaNGiLFq0KD/60Y9GeXIAAAAAAMaK8dUeYN26dVm2bFmam5uTJO3t7dmyZUs2bdqUW265ZdD1f/d3f5d3vetdufnmm5Mkt912Wx544IHccccdaW9vH3T9sWPHcuzYsf7fDx8+nCQ5cuTIkObtOfbCkPadKpxLZc5lMGdSmXOpzLlU5lwGcyaVOZfKnEtlzmUwZ1KZc6nMuVTmXAZzJpU5l8qcS2XOZTBnMlBP9//9X319faPyeTV9o/VJFXR3d+f000/Pvffem0WLFvWvL126NIcOHco3v/nNQXt+93d/Ny0tLbnxxhv711pbW3PfffflBz/4waDrP/7xj2fNmjUjMT4AAAAAACNs9+7dmT179oh/TlUfw3Lw4MH09PSkoaFhwHpDQ0M6Ozsr7uns7Dyh61euXJnDhw/3v55++unhGR4AAAAAgBE3fvzoPCCl6o9hGWl1dXWpq6ur9hgAAAAAAAxBbe3o3PNd1TvLJ02alHHjxqWrq2vAeldXV6ZOnVpxz9SpU0/oegAAAAAA+G2qGssnTJiQuXPnpqOjo3+tt7c3HR0daWxsrLinsbFxwPVJ8sADD7zi9QAAAAAA8NtU/TEsLS0tWbp0aebNm5fLLrss69evz9GjR9Pc3JwkWbJkSWbMmJG2trYkyQ033JA/+ZM/ydq1a/Oe97wn99xzT77//e/nzjvvPK7Pq6uryw033JCNGzeO2reoDlVfX1+6u7szYcKE1NTUVHuck4ZzGcyZVOZcKnMulTmXwZxJZc6lMudSmXMZzJlU5lwqcy6VOZfBnEllzqUy51KZcxnMmVQ2mudSU1OTc889N5MmTRrRz+n/vL6ToBjfcccd+exnP5vOzs7MmTMnf//3f5/58+cnSS6//PLMmjUrd999d//1X/3qV3Prrbdmz549ufDCC/OZz3wmV155ZZWmBwAAAADgVHdSxHIAAAAAAKimqj6zHAAAAAAATgZiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxld7gNHw3ve+N1/72teqPQYAAAAAAKOgpqYmvb29J7SniDvLn3322dTWFvGvAgAAAAAUraamJklyxx13nNi+vr6+vpEY6GR05pln5pe//GX/7xdccEGeeOKJKk4EAAAAAMBIOO+887J3797+eP7bFHO7dXd394BQnkQoBwAAAAAYg97whjfkf/7nf/L0008f955iYvnBgwerPQIAAAAAAKNgz549SZJnnnnmuPcUE8sBAAAAAChDd3d3kpzQd1kWE8snTZpU7REAAAAAABhF559//nFfW0wsnzBhQs4888xqjwEAAAAAwCi48MILM3ny5OO+vohY/sMf/jBXX311nnvuuWqPAgAAAADAKLjrrrtO6Pqavr6+vhGa5aTx53/+57nvvvuqPQYAAAAAAKPgrrvuyrXXXntCe4qI5QAAAAAA8GqKeAwLAAAAAAC8GrEcAAAAAIDiieUAAAAAABRPLAcAAAAAoHhiOQAAAAAAxRPLAQAAAAAonlgOAAAAAEDxxHIAAAAAAIonlgMAAAAAUDyxHAAAAACA4onlAAAAAAAU7/8DtDQ8VTHijuIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H6hwlBba6e5_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "x=tf.keras.preprocessing.sequence.pad_sequences(x ,padding='post')\n",
        "\n",
        "#for conv2d new dimansion to adapt MFCC inputs for convolutional layers.\n",
        "x=x[..., np.newaxis]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XbdIlb6h6Ani"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV9qKvGaFgvp"
      },
      "source": [
        "//CNN / LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "itYuWWoAPjg8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "skkvQQJwN1oH"
      },
      "outputs": [],
      "source": [
        "X_train = (X_train - X_train.mean()) / X_train.std()\n",
        "X_test  = (X_test  - X_train.mean()) / X_train.std()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P517s3qCN6CM",
        "outputId": "86c2e35b-86aa-49ff-c700-c65a8164812b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([640, 640, 640, 640, 640, 640, 640])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "np.bincount(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9_wacgGEtan"
      },
      "source": [
        "MFCC features have limited frequency resolution, so aggressive pooling across both axes may collapse feature maps.\n",
        "We therefore apply pooling mainly along the time axis and preserve frequency information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "XrUzzahxEms3",
        "outputId": "a98f6406-833e-4d3b-c05e-98e2818a4943"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │         \u001b[38;5;34m1,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │       \u001b[38;5;34m131,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m5120\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m5,506,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,506,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,672,903\u001b[0m (21.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,672,903</span> (21.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,672,519\u001b[0m (21.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,672,519</span> (21.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, BatchNormalization,\n",
        "    TimeDistributed, Flatten,\n",
        "    LSTM, Dense, Dropout\n",
        ")\n",
        "num_classes= len(np.unique(y))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=X_train.shape[1:]))\n",
        "\n",
        "# CNN block 1\n",
        "model.add(Conv2D(64, (4, 4), activation='relu', padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 1)))  # ↓ time only (1-2)=-1\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CNN block 2 (SAFE kernel)\n",
        "model.add(Conv2D(128, (4, 4), activation='relu', padding='same'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Prepare for LSTM\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "# LSTM\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#output\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYYOn2hEJWx7",
        "outputId": "c7f2797f-83c6-40b7-df2b-b8b1999a6e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n"
          ]
        }
      ],
      "source": [
        "print(y_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=30,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BgsgpvN1YQ9",
        "outputId": "1c33c72b-0af7-4ac1-fc4c-fc0a65d20498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m 88/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7:04\u001b[0m 18s/step - accuracy: 0.2860 - loss: 1.8724"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7at6h0EG9BjZ"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwDlyrgH9Wx3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Emotion Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsxyh3yH9FCU"
      },
      "outputs": [],
      "source": [
        "print(classification_report( y_test, y_pred, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n"
      ],
      "metadata": {
        "id": "rxa2NLqp6EmP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeWxK0b0H8fqIEK9vbf5pl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}